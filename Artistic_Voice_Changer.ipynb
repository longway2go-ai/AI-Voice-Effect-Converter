{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMcaXCyAqK2g",
        "outputId": "f4fb00c1-4211-418e-d5c3-d19dff8f1f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "# AI Voice Converter Pro - Gradio Version (Fastest Performance)\n",
        "# Optimized for Google Colab deployment\n",
        "\n",
        "# ===============================\n",
        "\n",
        "!pip install -q gradio yt-dlp librosa soundfile scipy numpy torch\n",
        "!apt-get update -qq && apt-get install -y -qq ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Ib9-Onvmw9eh",
        "outputId": "76c7dbcb-49ca-4dbb-c52b-2eab56754e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://70ea88810db53096c3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://70ea88810db53096c3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import yt_dlp\n",
        "import os\n",
        "import warnings\n",
        "import gc\n",
        "import time\n",
        "import hashlib\n",
        "import tempfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from scipy.signal import butter, filtfilt, hilbert\n",
        "from scipy import ndimage\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup directories\n",
        "TEMP_DIR = \"/tmp/voice_temp\"\n",
        "OUTPUT_DIR = \"/tmp/voice_output\"\n",
        "CACHE_DIR = \"/tmp/voice_cache\"\n",
        "\n",
        "for directory in [TEMP_DIR, OUTPUT_DIR, CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# ==============================\n",
        "# Enhanced Voice Effect Modeling\n",
        "# ==============================\n",
        "class OptimizedVoiceModeler:\n",
        "    @staticmethod\n",
        "    def animated_voice_processing(vocals, sr):\n",
        "        \"\"\"Bright, energetic animated voice (formerly female voice)\"\"\"\n",
        "        # 1. Higher pitch for animated character\n",
        "        vocals = librosa.effects.pitch_shift(vocals, sr=sr, n_steps=9)\n",
        "\n",
        "        # 2. Slight speed increase for energy\n",
        "        vocals = librosa.effects.time_stretch(vocals, rate=1.15)\n",
        "\n",
        "        # 3. Boost high-mid frequencies for brightness\n",
        "        b_bright, a_bright = butter(2, [2000, 5000], btype='band', fs=sr)\n",
        "        bright_boost = filtfilt(b_bright, a_bright, vocals) * 1.6\n",
        "        min_len = min(len(vocals), len(bright_boost))\n",
        "        vocals = vocals[:min_len] + bright_boost[:min_len] * 0.35\n",
        "\n",
        "        # 4. Add sparkle for animation\n",
        "        b_sparkle, a_sparkle = butter(1, 4000, btype='high', fs=sr)\n",
        "        sparkle = filtfilt(b_sparkle, a_sparkle, vocals) * 1.4\n",
        "        min_len = min(len(vocals), len(sparkle))\n",
        "        vocals = vocals[:min_len] + sparkle[:min_len] * 0.25\n",
        "\n",
        "        # 5. Reduce muddy low frequencies\n",
        "        b_clean, a_clean = butter(3, 300, btype='high', fs=sr)\n",
        "        vocals = filtfilt(b_clean, a_clean, vocals)\n",
        "\n",
        "        # 6. Animated character vibrato\n",
        "        vibrato_freq = 6.0\n",
        "        vibrato_depth = 0.025\n",
        "        t = np.arange(len(vocals)) / sr\n",
        "        vibrato = np.sin(2 * np.pi * vibrato_freq * t) * vibrato_depth\n",
        "        vocals = vocals * (1 + vibrato * 0.4)\n",
        "\n",
        "        # 7. Energetic compression\n",
        "        vocals = np.tanh(vocals * 1.4) * 0.88\n",
        "\n",
        "        return librosa.util.normalize(vocals) * 0.9\n",
        "\n",
        "    @staticmethod\n",
        "    def chipmunk_processing(vocals, sr):\n",
        "        \"\"\"High-pitched squeaky chipmunk voice - reduced music bleed\"\"\"\n",
        "        # 1. Very high pitch shift\n",
        "        vocals = librosa.effects.pitch_shift(vocals, sr=sr, n_steps=16)\n",
        "\n",
        "        # 2. Speed up for cartoon effect\n",
        "        vocals = librosa.effects.time_stretch(vocals, rate=1.4)\n",
        "\n",
        "        # 3. Focus only on very high frequencies to reduce music\n",
        "        b_squeak, a_squeak = butter(4, 3500, btype='high', fs=sr)\n",
        "        vocals = filtfilt(b_squeak, a_squeak, vocals)\n",
        "\n",
        "        # 4. Boost ultra-high frequencies\n",
        "        b_ultra, a_ultra = butter(2, [4000, 8000], btype='band', fs=sr)\n",
        "        ultra_boost = filtfilt(b_ultra, a_ultra, vocals) * 2.0\n",
        "        min_len = min(len(vocals), len(ultra_boost))\n",
        "        vocals = vocals[:min_len] + ultra_boost[:min_len] * 0.6\n",
        "\n",
        "        # 5. Completely remove low frequencies to eliminate music bleed\n",
        "        b_highpass, a_highpass = butter(6, 1000, btype='high', fs=sr)\n",
        "        vocals = filtfilt(b_highpass, a_highpass, vocals)\n",
        "\n",
        "        # 6. Sharp compression for cartoon effect\n",
        "        vocals = np.tanh(vocals * 3.5) * 0.75\n",
        "\n",
        "        # 7. Chipmunk vibrato\n",
        "        vibrato_freq = 8.5\n",
        "        vibrato_depth = 0.04\n",
        "        t = np.arange(len(vocals)) / sr\n",
        "        vibrato = np.sin(2 * np.pi * vibrato_freq * t) * vibrato_depth\n",
        "        vocals = vocals * (1 + vibrato)\n",
        "\n",
        "        return librosa.util.normalize(vocals) * 0.85\n",
        "\n",
        "    @staticmethod\n",
        "    def slowed_reverb_processing(vocals, sr):\n",
        "        \"\"\"Improved slowed + reverb - less slow, more atmospheric\"\"\"\n",
        "        # 1. Gentle pitch down for warmth (reduced from -2 to -1)\n",
        "        vocals = librosa.effects.pitch_shift(vocals, sr=sr, n_steps=-1)\n",
        "\n",
        "        # 2. Less extreme slowdown for better delivery (0.90 instead of 0.82)\n",
        "        vocals = librosa.effects.time_stretch(vocals, rate=0.90)\n",
        "\n",
        "        # 3. Enhanced echo chamber style reverb with more complex delays\n",
        "        reverb_vocals = vocals.copy()\n",
        "        delays = [int(0.04 * sr), int(0.08 * sr), int(0.15 * sr), int(0.28 * sr), int(0.42 * sr), int(0.6 * sr)]\n",
        "\n",
        "        for i, delay in enumerate(delays):\n",
        "            if delay < len(vocals):\n",
        "                delayed = np.pad(vocals, (delay, 0))[:len(vocals)]\n",
        "                decay = 0.6 * (0.75 ** i)  # Stronger initial reverb\n",
        "                reverb_vocals += delayed * decay\n",
        "\n",
        "        # 4. More atmospheric mix with enhanced reverb\n",
        "        vocals = vocals * 0.45 + reverb_vocals * 0.55\n",
        "\n",
        "        # 5. Warm, spacious filtering with enhanced low-mid warmth\n",
        "        b_warm, a_warm = butter(2, [180, 4000], btype='band', fs=sr)\n",
        "        warm_vocals = filtfilt(b_warm, a_warm, vocals) * 1.2\n",
        "        min_len = min(len(vocals), len(warm_vocals))\n",
        "        vocals = vocals[:min_len] + warm_vocals[:min_len] * 0.3\n",
        "\n",
        "        # 6. Add subtle chorus effect for depth\n",
        "        chorus_delay = int(0.02 * sr)\n",
        "        if chorus_delay < len(vocals):\n",
        "            chorus = np.pad(vocals, (chorus_delay, 0))[:len(vocals)]\n",
        "            vocals = vocals * 0.8 + chorus * 0.2\n",
        "\n",
        "        # 7. Gentle saturation for warmth\n",
        "        vocals = np.tanh(vocals * 1.2) * 0.9\n",
        "\n",
        "        return librosa.util.normalize(vocals) * 0.87\n",
        "\n",
        "    @staticmethod\n",
        "    def party_banger_processing(vocals, sr):\n",
        "        \"\"\"ENHANCED Party Mashup - Fixed version without repetitive high-freq noise\"\"\"\n",
        "\n",
        "        def safe_frequency(freq, sr):\n",
        "            nyquist = sr / 2\n",
        "            return max(1, min(freq, nyquist - 1))\n",
        "\n",
        "        def safe_bandpass(low, high, sr):\n",
        "            nyquist = sr / 2\n",
        "            low = max(1, min(low, nyquist - 2))\n",
        "            high = max(low + 1, min(high, nyquist - 1))\n",
        "            return [low, high]\n",
        "\n",
        "        # Keep original vocals untouched\n",
        "        original_vocals = vocals.copy()\n",
        "\n",
        "        # ============ RHYTHM SECTION (FIXED) ============\n",
        "\n",
        "        # 1. KICK DRUM (clean, no high-freq artifacts)\n",
        "        kick_drums = np.zeros_like(vocals)\n",
        "        kick_length = int(0.15 * sr)\n",
        "        for beat_pos in range(0, len(vocals), int(0.5 * sr)):\n",
        "            if beat_pos + kick_length < len(vocals):\n",
        "                t_kick = np.arange(kick_length) / sr\n",
        "                # Focus on low frequencies only for kick\n",
        "                kick_drum = (np.sin(2 * np.pi * 55 * t_kick) * 0.8 +\n",
        "                            np.sin(2 * np.pi * 80 * t_kick) * 0.4) * np.exp(-8 * t_kick) * np.hanning(kick_length)\n",
        "                kick_drums[beat_pos:beat_pos+kick_length] += kick_drum * 0.8\n",
        "\n",
        "        # 2. SNARE DRUM (reduced high frequencies)\n",
        "        snare_drums = np.zeros_like(vocals)\n",
        "        snare_length = int(0.08 * sr)\n",
        "        for snare_pos in range(int(1.0 * sr), len(vocals), int(1.0 * sr)):\n",
        "            if snare_pos + snare_length < len(vocals):\n",
        "                snare_noise = np.random.normal(0, 0.4, snare_length)\n",
        "                # FIXED: Lower high-freq cutoff to prevent chirping\n",
        "                snare_freq = safe_bandpass(300, 4000, sr)  # Was 8000\n",
        "                b_snare, a_snare = butter(2, snare_freq, btype='band', fs=sr)\n",
        "                snare = filtfilt(b_snare, a_snare, snare_noise) * np.exp(-8 * np.arange(snare_length) / sr)\n",
        "                snare_drums[snare_pos:snare_pos+snare_length] += snare * 0.6\n",
        "\n",
        "        # 3. REMOVE HI-HATS (main source of chirping sound)\n",
        "        # Hi-hats removed completely to eliminate chirping\n",
        "\n",
        "        # ============ BASS AND MELODIC ELEMENTS ============\n",
        "\n",
        "        # 4. BASS LINE (unchanged - low frequencies)\n",
        "        bass_line = np.zeros_like(vocals)\n",
        "        bass_length = int(0.35 * sr)\n",
        "        bass_pattern = [65, 82, 73, 55]  # Simplified pattern\n",
        "        bass_interval = int(0.8 * sr)  # Less frequent\n",
        "\n",
        "        for i, bass_pos in enumerate(range(0, len(vocals), bass_interval)):\n",
        "            if bass_pos + bass_length < len(vocals):\n",
        "                freq = bass_pattern[i % len(bass_pattern)]\n",
        "                t_bass = np.arange(bass_length) / sr\n",
        "                bass_note = (np.sin(2 * np.pi * freq * t_bass) * 0.7 +\n",
        "                            np.sin(2 * np.pi * freq * 2 * t_bass) * 0.3) * np.hanning(bass_length)\n",
        "                bass_line[bass_pos:bass_pos+bass_length] += bass_note * 0.6\n",
        "\n",
        "        # 5. LEAD MELODY (reduced frequency range)\n",
        "        lead_melody = np.zeros_like(vocals)\n",
        "        lead_length = int(0.3 * sr)  # Longer notes\n",
        "        melody_notes = [262, 294, 330, 349]  # Lower octave: C-D-E-F\n",
        "        melody_interval = int(1.2 * sr)  # Less frequent\n",
        "\n",
        "        for i, lead_pos in enumerate(range(int(0.4 * sr), len(vocals), melody_interval)):\n",
        "            if lead_pos + lead_length < len(vocals):\n",
        "                freq = melody_notes[i % len(melody_notes)]\n",
        "                t_lead = np.arange(lead_length) / sr\n",
        "                # Smoother envelope, no vibrato to prevent artifacts\n",
        "                lead_note = np.sin(2 * np.pi * freq * t_lead) * np.hanning(lead_length)\n",
        "                lead_melody[lead_pos:lead_pos+lead_length] += lead_note * 0.35\n",
        "\n",
        "        # 6. CHORD PADS (low-mid frequencies only)\n",
        "        pad_synth = np.zeros_like(vocals)\n",
        "        pad_length = int(4 * sr)\n",
        "        for pad_pos in range(0, len(vocals), int(8 * sr)):\n",
        "            if pad_pos + pad_length < len(vocals):\n",
        "                t_pad = np.arange(pad_length) / sr\n",
        "                # Lower frequency chord\n",
        "                pad_chord = (np.sin(2 * np.pi * 110 * t_pad) +\n",
        "                            np.sin(2 * np.pi * 138.5 * t_pad) +\n",
        "                            np.sin(2 * np.pi * 165 * t_pad)) * 0.06\n",
        "                # Smooth envelope\n",
        "                envelope = np.ones(pad_length)\n",
        "                fade_time = int(1.5 * sr)\n",
        "                envelope[:fade_time] = np.linspace(0, 1, fade_time)\n",
        "                envelope[-fade_time:] = np.linspace(1, 0, fade_time)\n",
        "                pad_synth[pad_pos:pad_pos+pad_length] += pad_chord * envelope\n",
        "\n",
        "        # 7. SIMPLE PLUCK (less frequent, lower pitch)\n",
        "        pluck_synth = np.zeros_like(vocals)\n",
        "        pluck_length = int(0.2 * sr)\n",
        "        pluck_notes = [220, 247, 277]  # A-B-C# (lower octave)\n",
        "        pluck_interval = int(2.0 * sr)  # Much less frequent\n",
        "\n",
        "        for i, pluck_pos in enumerate(range(int(1.0 * sr), len(vocals), pluck_interval)):\n",
        "            if pluck_pos + pluck_length < len(vocals):\n",
        "                freq = pluck_notes[i % len(pluck_notes)]\n",
        "                t_pluck = np.arange(pluck_length) / sr\n",
        "                pluck_note = np.sin(2 * np.pi * freq * t_pluck) * np.exp(-6 * t_pluck) * np.hanning(pluck_length)\n",
        "                pluck_synth[pluck_pos:pluck_pos+pluck_length] += pluck_note * 0.25\n",
        "\n",
        "        # ============ CONTROLLED EFFECTS ============\n",
        "\n",
        "        # 8. GENTLE SWEEPS (lower frequency range)\n",
        "        sweep_effects = np.zeros_like(vocals)\n",
        "        sweep_length = int(3 * sr)\n",
        "        for sweep_pos in range(0, len(vocals), int(16 * sr)):\n",
        "            if sweep_pos + sweep_length < len(vocals):\n",
        "                t_sweep = np.arange(sweep_length) / sr\n",
        "                # FIXED: Lower frequency range to prevent chirping\n",
        "                freq_sweep = 80 + (800 * t_sweep / (sweep_length / sr))  # Was 100-2000\n",
        "                sweep_sound = np.sin(2 * np.pi * freq_sweep * t_sweep) * 0.1\n",
        "                envelope = (np.linspace(0, 1, sweep_length) * np.linspace(1, 0, sweep_length)) ** 2\n",
        "                sweep_effects[sweep_pos:sweep_pos+sweep_length] += sweep_sound * envelope\n",
        "\n",
        "        # ============ FINAL MIX ============\n",
        "        party_mix = (original_vocals * 1.0 +\n",
        "                    kick_drums * 0.8 +\n",
        "                    snare_drums * 0.6 +\n",
        "                    bass_line * 0.7 +\n",
        "                    lead_melody * 0.5 +\n",
        "                    pad_synth * 0.4 +\n",
        "                    pluck_synth * 0.4 +\n",
        "                    sweep_effects * 0.3)\n",
        "\n",
        "        # ============ POST-PROCESSING TO REMOVE ARTIFACTS ============\n",
        "\n",
        "        # Apply notch filter to remove any remaining high-frequency artifacts\n",
        "        from scipy.signal import iirnotch\n",
        "\n",
        "        # Remove potential chirping frequencies\n",
        "        for notch_freq in [4500, 5500, 6500]:  # Common chirping frequencies\n",
        "            if notch_freq < sr/2:\n",
        "                b_notch, a_notch = iirnotch(notch_freq, 30, sr)\n",
        "                party_mix = filtfilt(b_notch, a_notch, party_mix)\n",
        "\n",
        "        # Gentle low-pass filter to remove any high-frequency noise\n",
        "        cutoff_freq = safe_frequency(8000, sr)\n",
        "        b_lpf, a_lpf = butter(2, cutoff_freq, btype='low', fs=sr)\n",
        "        party_mix = filtfilt(b_lpf, a_lpf, party_mix)\n",
        "\n",
        "        # Final limiting\n",
        "        party_mix = np.tanh(party_mix * 1.1) * 0.9\n",
        "\n",
        "        return librosa.util.normalize(party_mix) * 0.85\n",
        "\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Downloader (unchanged)\n",
        "# ==============================\n",
        "class FastDownloader:\n",
        "    def __init__(self):\n",
        "        self.max_duration = 90\n",
        "        self.cache_dir = CACHE_DIR\n",
        "\n",
        "    def download_audio_fast(self, url, filename=\"audio\", progress_callback=None):\n",
        "        try:\n",
        "            if progress_callback:\n",
        "                progress_callback(0.1, \"Starting download...\")\n",
        "\n",
        "            url_hash = hashlib.md5(url.encode()).hexdigest()[:8]\n",
        "            cache_path = os.path.join(self.cache_dir, f\"{url_hash}.wav\")\n",
        "\n",
        "            if os.path.exists(cache_path):\n",
        "                if progress_callback:\n",
        "                    progress_callback(0.3, \"Loading from cache...\")\n",
        "                output_path = os.path.join(TEMP_DIR, f\"{filename}.wav\")\n",
        "                shutil.copy2(cache_path, output_path)\n",
        "                try:\n",
        "                    with open(os.path.join(self.cache_dir, f\"{url_hash}_title.txt\"), 'r') as f:\n",
        "                        title = f.read().strip()\n",
        "                except:\n",
        "                    title = \"Cached Audio\"\n",
        "                return output_path, title\n",
        "\n",
        "            output_path = os.path.join(TEMP_DIR, f\"{filename}.wav\")\n",
        "            strategies = [\n",
        "                self._try_embedded_client,\n",
        "                self._try_android_client,\n",
        "                self._try_web_client,\n",
        "                self._try_basic_client\n",
        "            ]\n",
        "\n",
        "            for i, strategy in enumerate(strategies):\n",
        "                try:\n",
        "                    if progress_callback:\n",
        "                        progress_callback(0.1 + i*0.05, f\"Trying method {i+1}...\")\n",
        "\n",
        "                    title = strategy(url, filename)\n",
        "                    if title:\n",
        "                        if progress_callback:\n",
        "                            progress_callback(0.25, f\"Downloaded: {title}\")\n",
        "\n",
        "                        y, sr = librosa.load(output_path, sr=22050, duration=self.max_duration)\n",
        "                        sf.write(output_path, y, sr)\n",
        "\n",
        "                        try:\n",
        "                            shutil.copy2(output_path, cache_path)\n",
        "                            with open(os.path.join(self.cache_dir, f\"{url_hash}_title.txt\"), 'w') as f:\n",
        "                                f.write(title)\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                        return output_path, title\n",
        "\n",
        "                except Exception as e:\n",
        "                    if progress_callback:\n",
        "                        progress_callback(0.1 + i*0.05, f\"Method {i+1} failed, trying next...\")\n",
        "                    continue\n",
        "\n",
        "            raise Exception(\"All download methods failed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Download failed: {str(e)}\")\n",
        "\n",
        "    def _try_embedded_client(self, url, filename):\n",
        "        output_path = os.path.join(TEMP_DIR, f\"{filename}.wav\")\n",
        "\n",
        "        ydl_opts = {\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "            'format': 'worstaudio[filesize<15M]/worst',\n",
        "            'outtmpl': os.path.join(TEMP_DIR, f\"{filename}.%(ext)s\"),\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '64',\n",
        "            }],\n",
        "            'postprocessor_args': ['-t', '90', '-ar', '22050'],\n",
        "            'http_headers': {\n",
        "                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36',\n",
        "            },\n",
        "            'extractor_args': {\n",
        "                'youtube': {\n",
        "                    'player_client': ['web_embedded_player', 'android_embedded_player'],\n",
        "                    'skip_age_gate': True,\n",
        "                }\n",
        "            },\n",
        "        }\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(url, download=True)\n",
        "            return info.get('title', 'Unknown')[:30]\n",
        "\n",
        "    def _try_android_client(self, url, filename):\n",
        "        output_path = os.path.join(TEMP_DIR, f\"{filename}.wav\")\n",
        "\n",
        "        ydl_opts = {\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "            'format': 'worstaudio/worst',\n",
        "            'outtmpl': os.path.join(TEMP_DIR, f\"{filename}.%(ext)s\"),\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '64',\n",
        "            }],\n",
        "            'postprocessor_args': ['-t', '90', '-ar', '22050'],\n",
        "            'http_headers': {\n",
        "                'User-Agent': 'com.google.android.youtube/18.11.34',\n",
        "            },\n",
        "            'extractor_args': {\n",
        "                'youtube': {\n",
        "                    'player_client': ['android', 'android_music'],\n",
        "                    'skip_age_gate': True,\n",
        "                }\n",
        "            },\n",
        "        }\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(url, download=True)\n",
        "            return info.get('title', 'Unknown')[:30]\n",
        "\n",
        "    def _try_web_client(self, url, filename):\n",
        "        output_path = os.path.join(TEMP_DIR, f\"{filename}.wav\")\n",
        "\n",
        "        ydl_opts = {\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "            'format': 'worstaudio/worst',\n",
        "            'outtmpl': os.path.join(TEMP_DIR, f\"{filename}.%(ext)s\"),\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '64',\n",
        "            }],\n",
        "            'postprocessor_args': ['-t', '90', '-ar', '22050'],\n",
        "        }\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(url, download=True)\n",
        "            return info.get('title', 'Unknown')[:30]\n",
        "\n",
        "    def _try_basic_client(self, url, filename):\n",
        "        output_path = os.path.join(TEMP_DIR, f\"{filename}.wav\")\n",
        "\n",
        "        ydl_opts = {\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "            'format': 'worst',\n",
        "            'outtmpl': os.path.join(TEMP_DIR, f\"{filename}.%(ext)s\"),\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '48',\n",
        "            }],\n",
        "            'postprocessor_args': ['-t', '90'],\n",
        "        }\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(url, download=True)\n",
        "            return info.get('title', 'Unknown')[:30]\n",
        "\n",
        "# ==============================\n",
        "# Enhanced Voice Effect Converter\n",
        "# ==============================\n",
        "class OptimizedVoiceConverter:\n",
        "    def __init__(self):\n",
        "        self.voice_modeler = OptimizedVoiceModeler()\n",
        "        self.styles = {\n",
        "            \"Animated Voice\": \"animated_voice_processing\",\n",
        "            \"Slowed + Reverb\": \"slowed_reverb_processing\",\n",
        "            \"Party Mashup\": \"party_banger_processing\",  # Updated name\n",
        "        }\n",
        "\n",
        "    def convert_voice_effect(self, youtube_url, voice_style, vocal_vol, music_vol, progress_fn):\n",
        "        start_time = time.time()\n",
        "        temp_id = str(int(time.time()) % 10000)\n",
        "\n",
        "        try:\n",
        "            downloader = FastDownloader()\n",
        "            audio_path, title = downloader.download_audio_fast(youtube_url, f\"input_{temp_id}\", progress_fn)\n",
        "\n",
        "            progress_fn(0.35, \"Advanced vocal separation...\")\n",
        "\n",
        "            y, sr = librosa.load(audio_path, sr=22050, mono=False)\n",
        "            vocals, instrumental = self._separate_vocals_optimized(y, sr, voice_style)\n",
        "\n",
        "            progress_fn(0.55, f\"Applying {voice_style} effect...\")\n",
        "\n",
        "            converted_vocals = self._apply_voice_effect(vocals, sr, voice_style)\n",
        "\n",
        "            progress_fn(0.75, \"Professional mixing...\")\n",
        "\n",
        "            final_mix = self._optimized_mix(converted_vocals, instrumental, vocal_vol, music_vol, sr, voice_style)\n",
        "\n",
        "            output_path = os.path.join(OUTPUT_DIR, f\"final_{temp_id}.wav\")\n",
        "            sf.write(output_path, final_mix, sr)\n",
        "\n",
        "            try:\n",
        "                os.remove(audio_path)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "            progress_fn(1.0, f\"{voice_style} effect complete! ({processing_time:.1f}s)\")\n",
        "\n",
        "            gc.collect()\n",
        "            return output_path, title, processing_time\n",
        "\n",
        "        except Exception as e:\n",
        "            for f in Path(TEMP_DIR).glob(f\"*{temp_id}*\"):\n",
        "                try:\n",
        "                    f.unlink()\n",
        "                except:\n",
        "                    pass\n",
        "            gc.collect()\n",
        "            raise Exception(f\"Conversion failed: {str(e)}\")\n",
        "\n",
        "    def convert_voice_effect_from_file(self, audio_file_path, voice_style, vocal_vol, music_vol, progress_fn):\n",
        "        start_time = time.time()\n",
        "        temp_id = str(int(time.time()) % 10000)\n",
        "\n",
        "        try:\n",
        "            progress_fn(0.1, \"Loading uploaded audio...\")\n",
        "\n",
        "            y, sr = librosa.load(audio_file_path, sr=22050, mono=False, duration=90)\n",
        "            vocals, instrumental = self._separate_vocals_optimized(y, sr, voice_style)\n",
        "\n",
        "            progress_fn(0.4, f\"Applying {voice_style} effect...\")\n",
        "\n",
        "            converted_vocals = self._apply_voice_effect(vocals, sr, voice_style)\n",
        "\n",
        "            progress_fn(0.75, \"Professional mixing...\")\n",
        "\n",
        "            final_mix = self._optimized_mix(converted_vocals, instrumental, vocal_vol, music_vol, sr, voice_style)\n",
        "\n",
        "            output_path = os.path.join(OUTPUT_DIR, f\"final_{temp_id}.wav\")\n",
        "            sf.write(output_path, final_mix, sr)\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "            progress_fn(1.0, f\"{voice_style} effect complete! ({processing_time:.1f}s)\")\n",
        "\n",
        "            gc.collect()\n",
        "            return output_path, \"Uploaded Audio\", processing_time\n",
        "\n",
        "        except Exception as e:\n",
        "            gc.collect()\n",
        "            raise Exception(f\"Conversion failed: {str(e)}\")\n",
        "\n",
        "    def _separate_vocals_optimized(self, y, sr, voice_style):\n",
        "        \"\"\"Optimized vocal separation based on voice style\"\"\"\n",
        "        if len(y.shape) == 2:\n",
        "            left, right = y[0], y[1]\n",
        "            min_len = min(len(left), len(right))\n",
        "            left, right = left[:min_len], right[:min_len]\n",
        "\n",
        "            mid = (left + right) / 2\n",
        "            side = (left - right) / 2\n",
        "\n",
        "            S_mid = librosa.stft(mid, n_fft=2048, hop_length=512)\n",
        "            magnitude = np.abs(S_mid)\n",
        "\n",
        "            freqs = librosa.fft_frequencies(sr=sr, n_fft=2048)\n",
        "            vocal_mask = np.ones_like(magnitude)\n",
        "\n",
        "            # Optimize separation based on voice style\n",
        "            if voice_style == \"Chipmunk\":\n",
        "                # Focus on higher frequencies for chipmunk to reduce music bleed\n",
        "                vocal_range = (freqs >= 200) & (freqs <= 6000)\n",
        "                vocal_mask[vocal_range] *= 2.5\n",
        "                vocal_mask[freqs < 200] *= 0.1\n",
        "                vocal_mask[freqs > 6000] *= 0.3\n",
        "            elif voice_style == \"Party Mashup\":\n",
        "                # Enhanced separation for party mashup\n",
        "                vocal_range = (freqs >= 100) & (freqs <= 5500)\n",
        "                vocal_mask[vocal_range] *= 2.2\n",
        "                vocal_mask[freqs < 100] *= 0.4\n",
        "                vocal_mask[freqs > 5500] *= 0.7\n",
        "            else:\n",
        "                # Standard separation for other effects\n",
        "                vocal_range = (freqs >= 80) & (freqs <= 5000)\n",
        "                vocal_mask[vocal_range] *= 2.0\n",
        "                vocal_mask[freqs < 80] *= 0.3\n",
        "                vocal_mask[freqs > 5000] *= 0.5\n",
        "\n",
        "            S_vocals = S_mid * vocal_mask\n",
        "            vocals_enhanced = librosa.istft(S_vocals, hop_length=512)\n",
        "\n",
        "            min_len = min(len(vocals_enhanced), len(side), len(mid))\n",
        "            vocals = (vocals_enhanced[:min_len] * 0.8 + side[:min_len] * 0.2)\n",
        "            instrumental = mid[:min_len] - vocals * 0.35\n",
        "\n",
        "        else:\n",
        "            S = librosa.stft(y, n_fft=2048)\n",
        "            magnitude = np.abs(S)\n",
        "\n",
        "            vocal_mask = np.ones_like(magnitude)\n",
        "            freqs = librosa.fft_frequencies(sr=sr, n_fft=2048)\n",
        "\n",
        "            if voice_style == \"Chipmunk\":\n",
        "                vocal_range = (freqs >= 200) & (freqs <= 6000)\n",
        "                vocal_mask[vocal_range] *= 2.2\n",
        "                vocal_mask[freqs < 200] *= 0.2\n",
        "            elif voice_style == \"Party Mashup\":\n",
        "                vocal_range = (freqs >= 100) & (freqs <= 5500)\n",
        "                vocal_mask[vocal_range] *= 1.9\n",
        "                vocal_mask[freqs < 100] *= 0.5\n",
        "            else:\n",
        "                vocal_range = (freqs >= 80) & (freqs <= 5000)\n",
        "                vocal_mask[vocal_range] *= 1.6\n",
        "                vocal_mask[freqs < 80] *= 0.4\n",
        "\n",
        "            vocals = librosa.istft(S * vocal_mask)\n",
        "\n",
        "            min_len = min(len(y), len(vocals))\n",
        "            vocals = vocals[:min_len]\n",
        "            instrumental = y[:min_len] - vocals * 0.3\n",
        "\n",
        "        return vocals, instrumental\n",
        "\n",
        "    def _apply_voice_effect(self, vocals, sr, style_name):\n",
        "        if style_name not in self.styles:\n",
        "            return vocals\n",
        "\n",
        "        processing_method = getattr(self.voice_modeler, self.styles[style_name])\n",
        "        return processing_method(vocals, sr)\n",
        "\n",
        "    def _optimized_mix(self, vocals, instrumental, vocal_vol, music_vol, sr, voice_style):\n",
        "        \"\"\"Enhanced mixing with style-specific optimizations\"\"\"\n",
        "        min_len = min(len(vocals), len(instrumental))\n",
        "        vocals = vocals[:min_len] * vocal_vol\n",
        "        instrumental = instrumental[:min_len] * music_vol\n",
        "\n",
        "        # Enhanced style-specific mixing\n",
        "        if voice_style == \"Chipmunk\":\n",
        "            # Reduce music more aggressively for chipmunk\n",
        "            try:\n",
        "                b_notch, a_notch = butter(3, [800, 4000], btype='band', fs=sr)\n",
        "                notch = filtfilt(b_notch, a_notch, instrumental)\n",
        "                min_len = min(len(instrumental), len(notch))\n",
        "                instrumental_ducked = instrumental[:min_len] - notch[:min_len] * 0.4\n",
        "            except:\n",
        "                instrumental_ducked = instrumental * 0.7\n",
        "        elif voice_style == \"Party Mashup\":\n",
        "            # Special processing for mashup style - enhance electronic feel\n",
        "            try:\n",
        "                # Boost bass and treble in instrumental for electronic feel\n",
        "                b_bass, a_bass = butter(2, 150, btype='low', fs=sr)\n",
        "                bass_boost = filtfilt(b_bass, a_bass, instrumental) * 1.3\n",
        "\n",
        "                b_treble, a_treble = butter(2, 8000, btype='high', fs=sr)\n",
        "                treble_boost = filtfilt(b_treble, a_treble, instrumental) * 1.2\n",
        "\n",
        "                # Duck only mid frequencies where vocals sit\n",
        "                b_notch, a_notch = butter(2, [800, 3500], btype='band', fs=sr)\n",
        "                notch = filtfilt(b_notch, a_notch, instrumental)\n",
        "\n",
        "                min_len = min(len(instrumental), len(notch), len(bass_boost), len(treble_boost))\n",
        "                instrumental_ducked = (instrumental[:min_len] - notch[:min_len] * 0.2 +\n",
        "                                    bass_boost[:min_len] * 0.15 + treble_boost[:min_len] * 0.1)\n",
        "            except:\n",
        "                instrumental_ducked = instrumental * 0.95\n",
        "        elif voice_style == \"Slowed + Reverb\":\n",
        "            # Enhance atmospheric mixing for slowed reverb\n",
        "            try:\n",
        "                # Gentle high-cut on instrumental for warmth\n",
        "                b_warm, a_warm = butter(2, 6000, btype='low', fs=sr)\n",
        "                warm_inst = filtfilt(b_warm, a_warm, instrumental)\n",
        "\n",
        "                # Light ducking in vocal range\n",
        "                b_notch, a_notch = butter(1, [1000, 2800], btype='band', fs=sr)\n",
        "                notch = filtfilt(b_notch, a_notch, instrumental)\n",
        "                min_len = min(len(warm_inst), len(notch))\n",
        "                instrumental_ducked = warm_inst[:min_len] - notch[:min_len] * 0.15\n",
        "            except:\n",
        "                instrumental_ducked = instrumental * 0.85\n",
        "        else:\n",
        "            # Standard ducking\n",
        "            try:\n",
        "                b_notch, a_notch = butter(2, [1200, 3000], btype='band', fs=sr)\n",
        "                notch = filtfilt(b_notch, a_notch, instrumental)\n",
        "                min_len = min(len(instrumental), len(notch))\n",
        "                instrumental_ducked = instrumental[:min_len] - notch[:min_len] * 0.25\n",
        "            except:\n",
        "                instrumental_ducked = instrumental\n",
        "\n",
        "        min_len = min(len(vocals), len(instrumental_ducked))\n",
        "        vocals = vocals[:min_len]\n",
        "        instrumental_ducked = instrumental_ducked[:min_len]\n",
        "\n",
        "        mixed = vocals + instrumental_ducked\n",
        "\n",
        "        # Style-specific final mastering\n",
        "        if voice_style == \"Party Mashup\":\n",
        "            # Add subtle stereo enhancement for electronic feel\n",
        "            max_val = np.max(np.abs(mixed))\n",
        "            if max_val > 0.85:\n",
        "                mixed = mixed / max_val * 0.85\n",
        "            mixed = np.tanh(mixed * 1.15) * 0.92\n",
        "        else:\n",
        "            max_val = np.max(np.abs(mixed))\n",
        "            if max_val > 0.9:\n",
        "                mixed = mixed / max_val * 0.9\n",
        "            mixed = np.tanh(mixed * 1.05) * 0.95\n",
        "\n",
        "        return mixed\n",
        "\n",
        "    def get_styles(self):\n",
        "        return list(self.styles.keys())\n",
        "\n",
        "# ==============================\n",
        "# Gradio Interface\n",
        "# ==============================\n",
        "converter = OptimizedVoiceConverter()\n",
        "\n",
        "def process_with_input(youtube_url, uploaded_file, voice_style, vocal_vol, music_vol, progress=gr.Progress()):\n",
        "    def update_progress(fraction, text):\n",
        "        progress(fraction, desc=text)\n",
        "\n",
        "    try:\n",
        "        if uploaded_file is not None:\n",
        "            output_path, title, processing_time = converter.convert_voice_effect_from_file(\n",
        "                uploaded_file, voice_style, vocal_vol, music_vol, update_progress\n",
        "            )\n",
        "        elif youtube_url and youtube_url.strip():\n",
        "            output_path, title, processing_time = converter.convert_voice_effect(\n",
        "                youtube_url.strip(), voice_style, vocal_vol, music_vol, update_progress\n",
        "            )\n",
        "        else:\n",
        "            return None, \"❌ Error: Please provide either a YouTube URL or upload an audio file\", \"\"\n",
        "\n",
        "        return output_path, f\"✅ {voice_style} effect applied in {processing_time:.1f}s\", f\"🎵 {title}\"\n",
        "    except Exception as e:\n",
        "        return None, f\"❌ Error: {str(e)}\", \"\"\n",
        "\n",
        "with gr.Blocks(\n",
        "    title=\"AI Voice Effect Converter\",\n",
        "    theme=gr.themes.Soft(),\n",
        "    css=\"\"\"\n",
        "        .effect-card { background: linear-gradient(45deg, #667eea, #764ba2); color: white;\n",
        "                      padding: 1rem; border-radius: 10px; margin: 0.5rem; text-align: center; }\n",
        "        .feature { background: #f8f9fa; padding: 1rem; border-radius: 8px; margin: 0.5rem;\n",
        "                  border-left: 4px solid #28a745; }\n",
        "    \"\"\"\n",
        ") as app:\n",
        "\n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"text-align: center; padding: 2rem; background: linear-gradient(135deg, #667eea, #764ba2); color: white; border-radius: 15px; margin-bottom: 2rem;\">\n",
        "        <h1 style=\"margin: 0; font-size: 2.5em;\">🎤 Enhanced Voice Effect Converter</h1>\n",
        "        <p style=\"margin: 1rem 0; font-size: 1.3em;\"> Improved Slowed Reverb • Party Mashup • Animated Voice</p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            youtube_input = gr.Textbox(\n",
        "                label=\"🎵 YouTube URL\",\n",
        "                placeholder=\"Paste YouTube URL for voice transformation...\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "            audio_file = gr.Audio(\n",
        "                label=\"📁 Or Upload Audio File\",\n",
        "                type=\"filepath\",\n",
        "                sources=[\"upload\"]\n",
        "            )\n",
        "\n",
        "            voice_style = gr.Dropdown(\n",
        "                choices=converter.get_styles(),\n",
        "                label=\"🎤 Voice Effect Style\",\n",
        "                value=\"Animated Voice\",\n",
        "                info=\"Choose from 3 voice effects\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                vocal_vol = gr.Slider(0.8, 2.0, 1.3, 0.1, label=\"🎙️ Voice Level\")\n",
        "                music_vol = gr.Slider(0.2, 1.0, 0.5, 0.1, label=\"🎵 Music Level\")\n",
        "\n",
        "            convert_btn = gr.Button(\"🎤 TRANSFORM VOICE\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            status_display = gr.Textbox(label=\"🔄 Processing Status\", lines=3)\n",
        "            file_info_display = gr.Textbox(label=\"📁 Track Info\", lines=2)\n",
        "            audio_output = gr.Audio(label=\"🎧 Voice Effect Output\")\n",
        "\n",
        "\n",
        "\n",
        "    gr.Examples([\n",
        "        [\"https://www.youtube.com/watch?v=L_jWHffIx5E\", \"Animated Voice\"],\n",
        "        [\"https://www.youtube.com/watch?v=JGwWNGJdvx8\", \"Slowed + Reverb\"],\n",
        "        [\"https://www.youtube.com/watch?v=example1\", \"Party Mashup\"],\n",
        "    ], inputs=[youtube_input, voice_style], label=\"🎯 Try These Examples\")\n",
        "\n",
        "    convert_btn.click(\n",
        "        fn=process_with_input,\n",
        "        inputs=[youtube_input, audio_file, voice_style, vocal_vol, music_vol],\n",
        "        outputs=[audio_output, status_display, file_info_display]\n",
        "    )\n",
        "\n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"margin-top: 2rem; padding: 1rem; background: linear-gradient(45deg, #ff6b6b, #4ecdc4); border-radius: 10px; text-align: center;\">\n",
        "        <p style=\"margin: 0; color: #2c3e50;\">\n",
        "            🎯 <strong>Enhanced Voice Effects</strong> • Party Mashup with electronic elements • Improved Slowed + Reverb timing\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0k_BhLrqQGH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9HtIvoQy_KI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
